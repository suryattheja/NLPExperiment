{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I wish to try to use the bigram approach. I gather all the bigrams in the corpus in the all2Grams dict. For every bigram, I keep a track of the frequency of thier occurances. However, if the bigram has a question word in it, then I inflate the count by multiplying it by k=5. \n",
    "As a result, when I take the top n bigrams, the bigrams that usually determine the type of question such as [what, is] etc are included in the training vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Question_Words = {'what', 'where', 'when','how','why','did','do','does','have','has','am','is','are','can','could','may','would','will','should'\n",
    "\"didn't\",\"doesn't\",\"haven't\",\"isn't\",\"aren't\",\"can't\",\"couldn't\",\"wouldn't\",\"won't\",\"shouldn't\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all2grams=dict()       #dict to store \n",
    "Gram2sentences=[]      #all sentence\n",
    "label1=[]              #primary labels\n",
    "label2=[]              #secondary labels\n",
    "lab1Count=1               \n",
    "lab2Count=1\n",
    "label1dict=dict()\n",
    "label2dict=dict()\n",
    "\n",
    "for line in open('training.data','r',encoding=\"ISO-8859-1\"):\n",
    "    line=[word.lower() for word in line.strip().split(' ')]\n",
    "    labels=line[0].split(':')\n",
    "    line=[word for word in line[1:] if word not in punctuation]\n",
    "    if(len(labels)!=2 or ' ' in line[0]):\n",
    "        print('Formatting asssumption wrong')\n",
    "        break\n",
    "    sentence2=[]\n",
    "    for i in range(int(len(line)/2)):\n",
    "        gram2=(line[i],line[i+1])\n",
    "        sentence2.append(gram2)\n",
    "        if(gram2 in all2grams):\n",
    "            if(gram2[0] in Question_Words):\n",
    "                all2grams[gram2]+=5\n",
    "            else:\n",
    "                all2grams[gram2]+=1\n",
    "        else:\n",
    "            if(gram2[0] in Question_Words):\n",
    "                all2grams[gram2]=5\n",
    "            else:\n",
    "                all2grams[gram2]=1\n",
    "    Gram2sentences.append(sentence2)         \n",
    "    \n",
    "    if(not(label1dict.get(labels[0],0))):\n",
    "        label1dict[labels[0]]=lab1Count\n",
    "        lab1Count+=1\n",
    "    if(not(label2dict.get(labels[1],0))):\n",
    "        label2dict[labels[1]]=lab2Count\n",
    "        lab2Count+=1\n",
    "    label1.append(label1dict[labels[0]])\n",
    "    label2.append(label2dict[labels[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popularTokens2gram=[x[0] for x in sorted(all2grams.items(),key=lambda x:x[1],reverse=True)[:500]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wordVec(sent):\n",
    "    vec=[]\n",
    "    for gram in popularTokens2gram:\n",
    "        if gram in sent:\n",
    "            vec.append(1)\n",
    "        else:\n",
    "            vec.append(0)\n",
    "    return vec   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the vector representations of all the sentences in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors2Gram=[wordVec(eachSentence) for eachSentence in Gram2sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainVectors=np.array(vectors2Gram[:int(0.6*len(vectors2Gram))])\n",
    "trainLabels1=np.array(label1[:int(0.6*len(vectors2Gram))])\n",
    "trainLabels2=np.array(label2[:int(0.6*len(vectors2Gram))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validVectors=np.array(vectors2Gram[int(0.6*len(vectors2Gram)):int(0.8*len(vectors2Gram))])\n",
    "validLabels1=np.array(label1[int(0.6*len(vectors2Gram)):int(0.8*len(vectors2Gram))])\n",
    "validLabels2=np.array(label2[int(0.6*len(vectors2Gram)):int(0.8*len(vectors2Gram))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "testVectors=np.array(vectors2Gram[int(0.8*len(vectors2Gram)):])\n",
    "testLabels1=np.array(label1[int(0.8*len(vectors2Gram)):])\n",
    "testLabels2=np.array(label2[int(0.8*len(vectors2Gram)):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7488673139158576\n",
      "0.7433656957928803\n",
      "0.7498381877022654\n"
     ]
    }
   ],
   "source": [
    "for c in [100,1000,10**5]:\n",
    "    clf=svm.SVC(C=c, kernel='rbf', gamma='auto', tol=0.001, class_weight='balanced', max_iter=-1,\\\n",
    "                decision_function_shape='ovr')\n",
    "    clf.fit(trainVectors,trainLabels1)\n",
    "    preds=clf.predict(validVectors)\n",
    "    accu=sum([1 if i==j else 0 for i,j in zip(preds,validLabels1)])/len(validLabels1)\n",
    "    print(accu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Choosing c=10**5 based on the above results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy obtained for primary label is  0.72662568747978\n"
     ]
    }
   ],
   "source": [
    "clf=svm.SVC(C=10**5, kernel='rbf', gamma='auto', tol=0.001, class_weight='balanced', max_iter=-1,\\\n",
    "                decision_function_shape='ovr')\n",
    "clf.fit(np.vstack([trainVectors,validVectors]),np.hstack([trainLabels1,validLabels1]))\n",
    "preds=clf.predict(testVectors)\n",
    "accu=sum([1 if i==j else 0 for i,j in zip(preds,testLabels1)])/len(testLabels1)\n",
    "print('Test accuracy obtained for primary label is ',accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5420711974110033\n",
      "0.6061488673139158\n",
      "0.6087378640776699\n"
     ]
    }
   ],
   "source": [
    "for c in [100,1000,10**5]:\n",
    "    clf=svm.SVC(C=c, kernel='rbf', gamma='auto', tol=0.001, class_weight='balanced', max_iter=-1,\\\n",
    "                decision_function_shape='ovr')\n",
    "    clf.fit(trainVectors,trainLabels2)\n",
    "    preds=clf.predict(validVectors)\n",
    "    accu=sum([1 if i==j else 0 for i,j in zip(preds,validLabels2)])/len(validLabels2)\n",
    "    print(accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy obtained for secondary label is 0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "clf=svm.SVC(C=10**5, kernel='rbf', gamma='auto', tol=0.001, class_weight='balanced', max_iter=-1,\\\n",
    "                decision_function_shape='ovr')\n",
    "clf.fit(np.vstack([trainVectors,validVectors]),np.hstack([trainLabels2,validLabels2]))\n",
    "preds=clf.predict(testVectors)\n",
    "accu=sum([1 if i==j else 0 for i,j in zip(preds,testLabels2)])/len(testLabels2)\n",
    "print(\"Test accuracy obtained for secondary label is\",accu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice that this model performs worse than the unigram model. As I glanced through the dataset, the reason became clear. The bigrams are not repeating enough. A few bigrams repeat very frequently, but most bigrams have a very low count. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
